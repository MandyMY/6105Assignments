{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a 6 layers Sequential Convolutional Neural Network for digits recognition trained on MNIST dataset. I choosed to build it with keras API (Tensorflow backend) which is very intuitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import keras\n",
    "import seaborn as sns\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv2D\n",
    "from keras.layers import MaxPool2D, Flatten, Dropout, ZeroPadding2D, BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.models import save_model, load_model\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train = pd.read_csv(\"../Datasets/train.csv\")\n",
    "test = pd.read_csv(\"../Datasets/test.csv\")\n",
    "y_train = train[\"label\"]\n",
    "x_train = train.drop(labels = [\"label\"], axis = 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I loaded more date from mnist in keras.datasets, can then combined them with the origin data provided. Because more training data means higher accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from mnist\n",
    "(x_train1, y_train1), (x_test1, y_test1) = mnist.load_data()\n",
    "train1 = np.concatenate([x_train1, x_test1], axis=0)\n",
    "y_train1 = np.concatenate([y_train1, y_test1], axis=0)\n",
    "x_train1 = train1.reshape(-1, 28*28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I perform a grayscale normalization to reduce the effect of illumination's differences.<br>\n",
    "Moreover the CNN converg faster on [0..1] data than on [0..255]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "x_train = x_train / 255.0\n",
    "x_train1 = x_train1 / 255.0\n",
    "test = test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all data\n",
    "x_train = np.concatenate((x_train, x_train1))\n",
    "y_train = np.concatenate((y_train, y_train1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.countplot(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have similar counts for the 10 digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test images (28px x 28px) has been stock into pandas.Dataframe as 1D vectors of 784 values. We reshape all data to 28x28x1 3D matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras requires an extra dimension in the end which correspond to channels. MNIST images are gray scaled so it use only one channel. For RGB images, there is 3 channels, we would have reshaped 784px vectors to 28x28x3 3D matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\n",
    "x_train = x_train.reshape(-1,28,28,1).astype('float32')\n",
    "test = test.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels are 10 digits numbers from 0 to 9. We need to encode these lables to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
    "y_train = np_utils.to_categorical(y_train,10).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I choosed to split the train set in two parts : a small fraction (10%) became the validation set which the model is evaluated and the rest (90%) is used to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train and the validation set for the fitting\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.1, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set attributions\n",
    "batch_size = 124\n",
    "n_filter = 32\n",
    "pool_size = (2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the Keras Sequential API, where you have just to add one layer at a time, starting from the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a 6 layers Sequential Convolutional Neural Network for digits recognition trained on MNIST dataset, includes the convolutional (Conv2D) layer, the pooling (MaxPool2D) layer, the ZeroPadding2D layer, the Flatten layer and two fully-connected (Dense) layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining convolutional and pooling layers, CNN are able to combine local features and learn more global features of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout is a regularization method, where a proportion of nodes in the layer are randomly ignored (setting their wieghts to zero) for each training sample. This drops randomly a propotion of the network and forces the network to learn features in a distributed way. This technique also improves generalization and reduces the overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'relu' is the rectifier (activation function max(0,x). The rectifier activation function is used to add non linearity to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Set the CNN model \n",
    "cnn_net = Sequential()\n",
    "\n",
    "cnn_net.add(Conv2D(32, kernel_size = (3,3), strides = (1,1),input_shape = (28,28,1)))\n",
    "cnn_net.add(Activation('relu'))\n",
    "cnn_net.add(BatchNormalization(epsilon = 1e-6, axis = 1))\n",
    "cnn_net.add(MaxPool2D(pool_size = pool_size))\n",
    "\n",
    "cnn_net.add(ZeroPadding2D((1,1)))\n",
    "cnn_net.add(Conv2D(48, kernel_size = (3,3)))\n",
    "cnn_net.add(Activation('relu'))\n",
    "cnn_net.add(BatchNormalization(epsilon = 1e-6, axis = 1))\n",
    "cnn_net.add(MaxPool2D(pool_size = pool_size))\n",
    "\n",
    "cnn_net.add(ZeroPadding2D((1,1)))\n",
    "cnn_net.add(Conv2D(64, kernel_size = (2,2)))\n",
    "cnn_net.add(Activation('relu'))\n",
    "cnn_net.add(BatchNormalization(epsilon = 1e-6, axis = 1))\n",
    "cnn_net.add(MaxPool2D(pool_size = pool_size))\n",
    "\n",
    "cnn_net.add(Dropout(0.25))\n",
    "cnn_net.add(Flatten())\n",
    "\n",
    "cnn_net.add(Dense(256))\n",
    "cnn_net.add(Activation('relu'))\n",
    "\n",
    "cnn_net.add(Dense(10))\n",
    "cnn_net.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 26, 26, 32)        104       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 13, 48)        13872     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 13, 13, 48)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 13, 13, 48)        52        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 48)          0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 8, 8, 48)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 7, 7, 64)          28        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               147712    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 177,010\n",
      "Trainable params: 176,918\n",
      "Non-trainable params: 92\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get dateils of model\n",
    "cnn_net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the loss function to measure how poorly our model performs on images with known labels. It is the error rate between the oberved labels and the predicted ones. We use a specific form for categorical classifications (>2 classes) called the \"categorical_crossentropy\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I choosed RMSprop (with default values), it is a very effective optimizer. The RMSProp update adjusts the Adagrad method in a very simple way in an attempt to reduce its aggressive, monotonically decreasing learning rate. We could also have used Stochastic Gradient Descent ('sgd') optimizer, but it is slower than RMSprop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I choosed RMSprop (with default values), it is a very effective optimizer. The RMSProp update adjusts the Adagrad method in a very simple way in an attempt to reduce its aggressive, monotonically decreasing learning rate. We could also have used Stochastic Gradient Descent ('sgd') optimizer, but it is slower than RMSprop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "cnn_net.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once our model is ready, we fit the training dataset ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 100800 samples, validate on 11200 samples\n",
      "Epoch 1/5\n",
      " - 256s - loss: 4.1594e-05 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 0.9997\n",
      "Epoch 2/5\n",
      " - 262s - loss: 7.2356e-05 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 0.9997\n",
      "Epoch 3/5\n",
      " - 248s - loss: 1.4107e-04 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 0.9997\n",
      "Epoch 4/5\n",
      " - 256s - loss: 3.0848e-05 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 0.9996\n",
      "Epoch 5/5\n",
      " - 251s - loss: 7.1178e-05 - acc: 1.0000 - val_loss: 0.0056 - val_acc: 0.9996\n",
      "Training Completely!\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "print('Start Training')\n",
    "cnn_net = load_model('../Models/cnn_net_model.h5')\n",
    "history = cnn_net.fit(x_train, y_train, batch_size=batch_size,\n",
    "    epochs=5,\n",
    "    verbose = 2,\n",
    "    shuffle=True,\n",
    "    validation_data=(x_val, y_val),\n",
    ")\n",
    "print('Training Completely!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result model after each times training will be saved to the path, it will be conveniently if you want to load a result model or if you want to continue your last training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "cnn_net.save('../Models/cnn_net_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28000/28000 [==============================] - 5s 171us/step\n"
     ]
    }
   ],
   "source": [
    "# Output the result.csv\n",
    "y_pred = cnn_net.predict_classes(test,batch_size=32,verbose=1)\n",
    "np.savetxt('../Datasets/result.csv',np.c_[range(1,len(y_pred)+1),y_pred],delimiter=',',header='ImageId,Label',comments='',fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differences from public kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loaded more data: \n",
    "    At In[3] to In[5], I loaded more date from mnist in keras.datasets, can then combined them with the origin data provided. Because more training data means higher accuracy. And on the other hand, handle origin data and make some changes, then combined the changed data with the origin data also can have the same effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add attribution \"shuffle\" in fit:\n",
    "    At In[14], I added shuffle attribution, it means whether to shuffle the training data before each epoch. It will improve the randomness of data and make the traing result more precise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model after training:\n",
    "    At In[15], I added model.save(/path), the result model after each times training will be saved to the path, it will be conveniently if you want to load a result model or if you want to continue your last training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
